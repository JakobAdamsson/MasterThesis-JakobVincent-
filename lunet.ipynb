{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilation_block(in_channels,out_channels):\n",
    "    block = Sequential(\n",
    "    Conv2d(in_channels,out_channels,kernel_size=(3,3),stride=1,padding=1,dilation=1), #A dilation of 1 requires only padding = 1 with kernelsize 3\n",
    "    BatchNorm2d(out_channels),\n",
    "    ReLU(inplace=True),\n",
    "    Conv2d(out_channels,out_channels,kernel_size=(3,3),stride=1,padding=1,dilation=1),\n",
    "    BatchNorm2d(out_channels),\n",
    "    ReLU(inplace=True),\n",
    "    Conv2d(out_channels,out_channels,kernel_size=(3,3),stride=1,padding=2,dilation=2),\n",
    "    BatchNorm2d(out_channels),\n",
    "    ReLU(inplace=True),\n",
    "    Conv2d(out_channels,out_channels,kernel_size=(3,3),stride=1,padding=2,dilation=2),\n",
    "    BatchNorm2d(out_channels),\n",
    "    ReLU(inplace=True)\n",
    "    )\n",
    "    return block\n",
    "\n",
    "from torch.nn import Conv2d,Sequential, ReLU, Linear, MaxPool2d, BatchNorm2d, ConvTranspose2d\n",
    "class L_U_Net(nn.Module):\n",
    "    def __init__(self,num_classes,num_filters) -> None:\n",
    "        super().__init__()\n",
    "        self.initial_layer = dilation_block(3,num_filters)\n",
    "        self.dil_block = dilation_block(num_filters,num_filters)\n",
    "        self.pooling = MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(num_filters, num_filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(num_filters, num_filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.expand_tconv = ConvTranspose2d(num_filters,num_filters,kernel_size=(2,2),stride=2)\n",
    "\n",
    "        self.expand_conv = Sequential(\n",
    "            nn.Conv2d(num_filters*2, num_filters, kernel_size=3, stride=1, padding=1), # numfilters*2 due to skip connections :)\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "        )\n",
    "        self.final_layer = Conv2d(num_filters,num_classes, kernel_size=1)\n",
    "    def forward(self,x):\n",
    "        dil1 = self.initial_layer(x)\n",
    "        pool1 = self.pooling(dil1)\n",
    "\n",
    "        dil2 = self.dil_block(pool1)\n",
    "        pool2 = self.pooling(dil2)\n",
    "\n",
    "        dil3 = self.dil_block(pool2)\n",
    "        pool3 = self.pooling(dil3)\n",
    "\n",
    "        dil4 = self.dil_block(pool3)\n",
    "        pool4 = self.pooling(dil4)\n",
    "\n",
    "        bottle_neck = self.bottleneck(pool4)\n",
    "\n",
    "        tconv1 = self.expand_tconv(bottle_neck)\n",
    "        skip1 = torch.cat((tconv1,dil4),dim=1)\n",
    "        conv1= self.expand_conv(skip1)\n",
    "\n",
    "        tconv2= self.expand_tconv(conv1)\n",
    "        skip2 = torch.cat((tconv2,dil3),dim=1)\n",
    "        conv2 = self.expand_conv(skip2)\n",
    "\n",
    "        tconv3 = self.expand_tconv(conv2)\n",
    "        skip3 = torch.cat((tconv3,dil2),dim=1)\n",
    "        conv3 = self.expand_conv(skip3)\n",
    "\n",
    "        tconv4 = self.expand_tconv(conv3)\n",
    "        skip4 = torch.cat((tconv4,dil1),dim=1)\n",
    "        conv4 = self.expand_conv(skip4)\n",
    "\n",
    "        return self.final_layer(conv4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 10, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_tensor = torch.randn(6, 3, 224, 224)  # (batch_size, channels, height, width)\n",
    "model = L_U_Net(num_classes=10, num_filters=16)\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "print(output_tensor.size())  # Output dimensions should match the input spatial dimensions but with num_classes channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def conv_block(in_channels, out_channels):\n",
    "    block = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "    return block\n",
    "def up_conv(in_channels, out_channels):\n",
    "    return  nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder1 = conv_block(3, 64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.encoder2 = conv_block(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.encoder3 = conv_block(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.encoder4 = conv_block(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = conv_block(512, 1024)\n",
    "\n",
    "        self.upconv1 = up_conv(1024, 512)\n",
    "        self.decoder1 = conv_block(1024, 512)\n",
    "\n",
    "        self.upconv2 = up_conv(512, 256)\n",
    "        self.decoder2 = conv_block(512, 256)\n",
    "\n",
    "        self.upconv3 = up_conv(256, 128)\n",
    "        self.decoder3 = conv_block(256, 128)\n",
    "\n",
    "        self.upconv4 = up_conv(128, 64)\n",
    "        self.decoder4 = conv_block(128, 64)\n",
    "\n",
    "        self.final_layer = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Contracting Path\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        # Expanding Path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        dec1 = self.upconv1(bottleneck)\n",
    "        skip1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(skip1)\n",
    "\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        skip2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(skip2)\n",
    "\n",
    "\n",
    "\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        skip3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(skip3)\n",
    "\n",
    "        dec4 = self.upconv4(dec3)\n",
    "        skip4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(skip4)\n",
    "\n",
    "        return self.final_layer(dec1)\n",
    "\n",
    "input_tensor = torch.randn(1, 3, 224, 224)  # (batch_size, channels, height, width)\n",
    "model = UNet(num_classes=10)\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "print(output_tensor.size())  # Output dimensions should be [1, num_classes, 224, 224]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
