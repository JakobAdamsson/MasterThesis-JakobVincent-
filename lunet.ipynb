{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 10, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Conv2d,Sequential, ReLU, Linear, MaxPool2d, BatchNorm2d, ConvTranspose2d,Upsample, Sigmoid\n",
    "\n",
    "def dilation_block(in_channels,out_channels):\n",
    "    block = Sequential(\n",
    "    Conv2d(in_channels,out_channels,kernel_size=(3,3),stride=1,padding=1,dilation=1,bias=False), #A dilation of 1 requires only padding = 1 with kernelsize 3, Norm contains bias\n",
    "    BatchNorm2d(out_channels),\n",
    "    ReLU(inplace=True),\n",
    "    Conv2d(out_channels,out_channels,kernel_size=(3,3),stride=1,padding=1,dilation=1,bias=False),\n",
    "    BatchNorm2d(out_channels),\n",
    "    ReLU(inplace=True),\n",
    "    Conv2d(out_channels,out_channels,kernel_size=(3,3),stride=1,padding=2,dilation=2,bias=False),\n",
    "    BatchNorm2d(out_channels),\n",
    "    ReLU(inplace=True),\n",
    "    Conv2d(out_channels,out_channels,kernel_size=(3,3),stride=1,padding=2,dilation=2,bias=False),\n",
    "    BatchNorm2d(out_channels),\n",
    "    ReLU(inplace=True)\n",
    "    )\n",
    "    return block\n",
    "def up_conv(in_channels, out_channels): # This is used to avoid checkerboard artefacts\n",
    "    return Sequential(\n",
    "        Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "        Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "        BatchNorm2d(out_channels),\n",
    "        ReLU(inplace=True)\n",
    "    )\n",
    "class L_U_Net(nn.Module):\n",
    "    def __init__(self,num_classes,num_filters) -> None:\n",
    "        super(L_U_Net,self).__init__()\n",
    "        self.initial_layer = dilation_block(3,num_filters)\n",
    "        self.dil_block = dilation_block(num_filters,num_filters)\n",
    "        self.pooling = MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(num_filters, num_filters, kernel_size=3, stride=1, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(num_filters, num_filters, kernel_size=3, stride=1, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.upsample = up_conv(num_filters,num_filters)\n",
    "        self.expand_conv = Sequential(\n",
    "            nn.Conv2d(num_filters*2, num_filters, kernel_size=3, stride=1, padding=1,bias=False), # numfilters*2 due to skip connections :)\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "        )\n",
    "        self.final_layer = Conv2d(num_filters,num_classes, kernel_size=1)\n",
    "    def forward(self,x):\n",
    "        dil1 = self.initial_layer(x)\n",
    "        pool1 = self.pooling(dil1)\n",
    "\n",
    "        dil2 = self.dil_block(pool1)\n",
    "        pool2 = self.pooling(dil2)\n",
    "\n",
    "        dil3 = self.dil_block(pool2)\n",
    "        pool3 = self.pooling(dil3)\n",
    "\n",
    "        dil4 = self.dil_block(pool3)\n",
    "        pool4 = self.pooling(dil4)\n",
    "\n",
    "        bottle_neck = self.bottleneck(pool4)\n",
    "\n",
    "        tconv1 = self.upsample(bottle_neck)\n",
    "        skip1 = torch.cat((tconv1,dil4),dim=1)\n",
    "        conv1= self.expand_conv(skip1)\n",
    "\n",
    "        tconv2= self.upsample(conv1)\n",
    "        skip2 = torch.cat((tconv2,dil3),dim=1)\n",
    "        conv2 = self.expand_conv(skip2)\n",
    "\n",
    "        tconv3 = self.upsample(conv2)\n",
    "        skip3 = torch.cat((tconv3,dil2),dim=1)\n",
    "        conv3 = self.expand_conv(skip3)\n",
    "\n",
    "        tconv4 = self.upsample(conv3)\n",
    "        skip4 = torch.cat((tconv4,dil1),dim=1)\n",
    "        conv4 = self.expand_conv(skip4)\n",
    "\n",
    "        return self.final_layer(conv4)\n",
    "\n",
    "# Example usage\n",
    "input_tensor = torch.randn(6, 3, 224, 224)  # (batch_size, channels, height, width)\n",
    "model = L_U_Net(num_classes=10, num_filters=16)\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "print(output_tensor.size())  # Output dimensions should match the input spatial dimensions but with num_classes channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "def conv_block(in_channels, out_channels):\n",
    "    block = nn.Sequential(\n",
    "        Conv2d(in_channels, out_channels, kernel_size=3, padding=1,bias=False),\n",
    "        BatchNorm2d(out_channels),\n",
    "        ReLU(inplace=True),\n",
    "        Conv2d(out_channels, out_channels, kernel_size=3, padding=1,bias=False),\n",
    "        BatchNorm2d(out_channels),\n",
    "        ReLU(inplace=True)\n",
    "    )\n",
    "    return block\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.maxpool = MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.encoder1 = conv_block(3, 64)\n",
    "        self.encoder2 = conv_block(64, 128)\n",
    "        self.encoder3 = conv_block(128, 256)\n",
    "        self.encoder4 = conv_block(256, 512)\n",
    "\n",
    "        self.bottleneck = conv_block(512, 1024)\n",
    "\n",
    "        self.upconv1 = up_conv(1024, 512)\n",
    "        self.decoder1 = conv_block(1024, 512)\n",
    "\n",
    "        self.upconv2 = up_conv(512, 256)\n",
    "        self.decoder2 = conv_block(512, 256)\n",
    "\n",
    "        self.upconv3 = up_conv(256, 128)\n",
    "        self.decoder3 = conv_block(256, 128)\n",
    "\n",
    "        self.upconv4 = up_conv(128, 64)\n",
    "        self.decoder4 = conv_block(128, 64)\n",
    "\n",
    "        self.final_layer = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Contracting Path\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.maxpool(enc1))\n",
    "        enc3 = self.encoder3(self.maxpool(enc2))\n",
    "        enc4 = self.encoder4(self.maxpool(enc3))\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(self.maxpool(enc4))\n",
    "\n",
    "        # Expanding Path\n",
    "        up1 = self.upconv1(bottleneck)\n",
    "        skip1 = torch.cat((up1, enc4), dim=1)\n",
    "        dec1 = self.decoder1(skip1)\n",
    "\n",
    "        up2 = self.upconv2(dec1)\n",
    "        skip2 = torch.cat((up2, enc3), dim=1)\n",
    "        dec2 = self.decoder2(skip2)\n",
    "\n",
    "        up3 = self.upconv3(dec2)\n",
    "        skip3 = torch.cat((up3, enc2), dim=1)\n",
    "        dec3 = self.decoder3(skip3)\n",
    "\n",
    "        up4 = self.upconv4(dec3)\n",
    "        skip4 = torch.cat((up4, enc1), dim=1)\n",
    "        dec4 = self.decoder4(skip4)\n",
    "\n",
    "        return self.final_layer(dec4)\n",
    "\n",
    "input_tensor = torch.randn(1, 3, 224, 224)  # (batch_size, channels, height, width)\n",
    "model = UNet(num_classes=10)\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "print(output_tensor.size())  # Output dimensions should be [1, num_classes, 224, 224]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "class Attention_block(nn.Module):\n",
    "    def __init__(self,F_g,F_l,F_int):\n",
    "        super(Attention_block,self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            BatchNorm2d(F_int)\n",
    "            )\n",
    "\n",
    "        self.W_x = Sequential(\n",
    "            Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = Sequential(\n",
    "            Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            BatchNorm2d(1),\n",
    "            Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.relu = ReLU(inplace=True)\n",
    "\n",
    "    def forward(self,g,x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "\n",
    "        return x*psi\n",
    "\n",
    "\n",
    "class Attention_U_Net(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels):\n",
    "        super(Attention_U_Net, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder1 = conv_block(in_channels, 64)\n",
    "        self.encoder2 = conv_block(64, 128)\n",
    "        self.encoder3 = conv_block(128, 256)\n",
    "        self.encoder4 = conv_block(256, 512)\n",
    "        self.encoder5 = conv_block(512, 1024)\n",
    "\n",
    "        self.up_conv5 = up_conv(1024, 512)\n",
    "        self.att5 = Attention_block(F_g=512, F_l=512, F_int=256)\n",
    "        self.decoder5 = conv_block(1024, 512)\n",
    "\n",
    "        self.up_conv4 = up_conv(512, 256)\n",
    "        self.att4 = Attention_block(F_g=256, F_l=256, F_int=128)\n",
    "        self.decoder4 = conv_block(512, 256)\n",
    "\n",
    "        self.up_conv3 = up_conv(256, 128)\n",
    "        self.att3 = Attention_block(F_g=128, F_l=128, F_int=64)\n",
    "        self.decoder3 = conv_block(256, 128)\n",
    "\n",
    "        self.up_conv2 = up_conv(128, 64)\n",
    "        self.att2 = Attention_block(F_g=64, F_l=64, F_int=32)\n",
    "        self.decoder2 = conv_block(128, 64)\n",
    "\n",
    "        self.final_layer = nn.Conv2d(64, num_classes, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.encoder1(x)\n",
    "        pool1 = self.maxpool(enc1)\n",
    "\n",
    "        enc2 = self.encoder2(pool1)\n",
    "        pool2 = self.maxpool(enc2)\n",
    "\n",
    "        enc3 = self.encoder3(pool2)\n",
    "        pool3 = self.maxpool(enc3)\n",
    "\n",
    "        enc4 = self.encoder4(pool3)\n",
    "        pool4 = self.maxpool(enc4)\n",
    "\n",
    "        enc5 = self.encoder5(pool4)\n",
    "\n",
    "        # Decoder I realised this naming convention is easier far too late, changing the previous ones would be painful\n",
    "        up5 = self.up_conv5(enc5)\n",
    "        att5 = self.att5(g=up5, x=enc4)\n",
    "        dec5 = self.decoder5(torch.cat((att5, up5), dim=1))\n",
    "\n",
    "        up4 = self.up_conv4(dec5)\n",
    "        att4 = self.att4(g=up4, x=enc3)\n",
    "        dec4 = self.decoder4(torch.cat((att4, up4), dim=1))\n",
    "\n",
    "        up3 = self.up_conv3(dec4)\n",
    "        att3 = self.att3(g=up3, x=enc2)\n",
    "        dec3 = self.decoder3(torch.cat((att3, up3), dim=1))\n",
    "\n",
    "        up2 = self.up_conv2(dec3)\n",
    "        att2 = self.att2(g=up2, x=enc1)\n",
    "        dec2 = self.decoder2(torch.cat((att2, up2), dim=1))\n",
    "\n",
    "        output = self.final_layer(dec2)\n",
    "\n",
    "        return output\n",
    "num_classes = 2\n",
    "in_channels = 3\n",
    "\n",
    "model = Attention_U_Net(num_classes, in_channels)\n",
    "input_image = torch.randn(1, 3, 224, 224)\n",
    "output = model(input_image)\n",
    "\n",
    "print(output.shape)  # Expected output shape: (1, num_classes, 224, 224)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
